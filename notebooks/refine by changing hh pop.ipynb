{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#changing HH pop at large area level, NOT swapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = pd.HDFStore(\"run592_hh_outway_refined_test.h5\", complib='zlib', complevel=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement = pd.read_csv(\"MonForecastHHPOPRefinement.csv\").set_index('b_city_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement.loc[5070, '2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ind in refinement[str(2020)].index:\n",
    "    print ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for year in ['2020', '2025', '2030', '2035', '2040', '2045']:\n",
    "    dfh = pd.merge(st['/' + year + '/households'],\n",
    "                   st['/' + year + '/buildings'][['b_city_id']], \n",
    "                   left_on='building_id',right_index=True, how='left')\n",
    "    \n",
    "    dfp = pd.merge(st['/' + year + '/persons'],\n",
    "                   dfh[['b_city_id']], \n",
    "                   left_on='household_id',right_index=True, how='left')\n",
    "    \n",
    "    for city_id in refinement[year].index:\n",
    "        dfpc = dfp.loc[(dfp.b_city_id == city_id) &  (dfp.relate>0)]\n",
    "        amount = refinement.loc[city_id, year]\n",
    "        pre = len(dfpc)\n",
    "        \n",
    "        print city_id, 'before: ', pre,  'add:', amount\n",
    "        \n",
    "        if amount >0:\n",
    "            p_add = dfpc.sample(amount)\n",
    "            p_add.index=range(dfp.index.max()+1, dfp.index.max()+1+len(p_add))\n",
    "            dfp = pd.concat([dfp,p_add])\n",
    "        elif amount<0:\n",
    "            p_remove = dfpc.sample(amount).index\n",
    "            dfp.drop(p_remove, inplace=True)\n",
    "            \n",
    "    \n",
    "   \n",
    "    dfh['persons'] = dfp.groupby('household_id').size()\n",
    "    dfh['workers'] = dfp.groupby('household_id').worker.sum()\n",
    "    dfh.fillna(0, inplace=True)\n",
    "    print 'after:', len(dfp), dfh.persons.sum()\n",
    "    \n",
    "    st['/' + year + '/households'] = dfh\n",
    "    st['/' + year + '/persons'] =  dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement.drop([5015,5020], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.append([],refinement.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat(refinement.index.values, refinement.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement.loc[np.append([],refinement.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfp.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addp.index=[dfp.index.max()+x for x in range(len(addp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfp = pd.concat([dfp,addp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "added.index=[1633176426+x for x in range(len(added))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hhpersons = dfp.groupby('household_id').size()\n",
    "workers = dfp.groupby('household_id').worker.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfh = st['/2015/households'].copy()\n",
    "dfh['persons'] = 0\n",
    "dfh['persons'] = hhpersons\n",
    "dfh['workers'] = 0\n",
    "dfh['workers'] = hhpersons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1633176426+range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement.columns.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year in refinement.columns.sort_values().unique():\n",
    "    print \"year\", year\n",
    "    b_city_id = hdf[str(year) + '/buildings'][['b_city_id']]\n",
    "    households = hdf[str(year) + '/households']\n",
    "    households_col = households.columns\n",
    "    households = pd.merge(households, b_city_id, left_on='building_id', right_index=True, how='left')\n",
    "    pre = households[households.b_city_id.isin(refinement.index)].groupby('b_city_id').persons.sum()\n",
    "    ref = refinement[year]\n",
    "    gole = pre + ref\n",
    "    while len(ref) > 0 and ref.abs().sum() > 0:\n",
    "        ref = ref[ref != 0].copy()\n",
    "        main_city = ref.abs().argmin()\n",
    "        target = ref.loc[main_city]\n",
    "        other_citys = ref[ref * target < 0]\n",
    "\n",
    "        hh_main = households[households.b_city_id == main_city]\n",
    "        hh_other = households[households.b_city_id.isin(other_citys.index)]\n",
    "        \n",
    "        sample_size = min(10 * abs(target), len(hh_main), len(hh_other))\n",
    "        \n",
    "        print year, main_city, target, len(hh_main), len(hh_other), sample_size\n",
    "\n",
    "        hh_main_sample = hh_main.sample(sample_size)\n",
    "        hh_other_sample = hh_other.sample(sample_size)\n",
    "        \n",
    "        corect_dir = (target * (hh_other_sample.persons.values - hh_main_sample.persons.values) > 0)\n",
    "        hh_main_sample = hh_main_sample[corect_dir]\n",
    "        hh_other_sample = hh_other_sample[corect_dir]\n",
    "        \n",
    "        corect_size = (abs(hh_other_sample.persons.values - hh_main_sample.persons.values) <= abs(target))\n",
    "        hh_main_sample = hh_main_sample[corect_size]\n",
    "        hh_other_sample = hh_other_sample[corect_size]\n",
    "        \n",
    "        fit = abs(hh_other_sample.persons.values - hh_main_sample.persons.values).cumsum() <= abs(target)\n",
    "        hh_main_sample = hh_main_sample[fit]\n",
    "        hh_other_sample = hh_other_sample[fit]\n",
    "\n",
    "        households.loc[hh_main_sample.index, 'building_id'] = hh_other_sample.building_id.values\n",
    "        households.loc[hh_main_sample.index, 'b_city_id'] = hh_other_sample.b_city_id.values\n",
    "        households.loc[hh_other_sample.index, 'building_id'] = hh_main_sample.building_id.values\n",
    "        households.loc[hh_other_sample.index, 'b_city_id'] = hh_main_sample.b_city_id.values\n",
    "        \n",
    "        post = households[households.b_city_id.isin(refinement.index)].groupby('b_city_id').persons.sum()\n",
    "        \n",
    "        ref = (gole - post).astype(int)\n",
    "    \n",
    "    hdf[str(year) + '/households'] = households[households_col]\n",
    "    print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
